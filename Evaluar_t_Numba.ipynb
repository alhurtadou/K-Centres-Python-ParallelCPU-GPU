{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "import math\n",
        "import numba\n",
        "import numpy as np\n",
        "\n",
        "@numba.cuda.jit\n",
        "def add_arrays_on_gpu(a, b, c):\n",
        "    i = numba.cuda.grid(1)\n",
        "    if i < a.shape[0]:\n",
        "        c[i] = i\n",
        "\n",
        "# Datos de entrada\n",
        "a = np.array([1, 2, 3, 4], dtype=np.int32)\n",
        "b = np.array([10, 20, 30, 40], dtype=np.int32)\n",
        "c = np.empty_like(a)\n",
        "\n",
        "# Configuración de la cuadrícula de hilos\n",
        "threads_per_block = 4\n",
        "blocks_per_grid = (a.shape[0] + (threads_per_block - 1)) // threads_per_block\n",
        "\n",
        "# Llamada a la función en la GPU\n",
        "add_arrays_on_gpu[blocks_per_grid, threads_per_block](a, b, c)\n",
        "\n",
        "print(c)\n"
      ],
      "metadata": {
        "id": "WjSSlsK_xfyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240cc0f6-6ba7-442e-c28a-b00316968a43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda\n",
        "\n",
        "# Función que suma dos matrices en la GPU\n",
        "@cuda.jit\n",
        "def add_matrices_on_gpu(A, B, C):\n",
        "    i, j = cuda.grid(2)\n",
        "    if i < A.shape[0] and j < A.shape[1]:\n",
        "        # C[i, j] =j\n",
        "        C[i, j] = A[i, j] + B[i, j]\n",
        "\n",
        "# Definir las dimensiones de las matrices\n",
        "rows = 3\n",
        "cols = 3\n",
        "\n",
        "# Crear dos matrices aleatorias en la CPU\n",
        "A=np.array([[0, 40, 50, 10, 80, 20],\n",
        "            [40, 0, 90, 30, 100, 80],\n",
        "            [50, 90, 0, 60, 30, 10],\n",
        "            [10, 30, 60, 0, 70, 40],\n",
        "            [80, 100, 30, 70, 0, 50],\n",
        "            [20, 80, 10, 40, 50, 0]]).astype(np.float32)\n",
        "\n",
        "B=np.array([[0, 40, 50, 10, 80, 20],\n",
        "            [40, 0, 90, 30, 100, 80],\n",
        "            [50, 90, 0, 60, 30, 10],\n",
        "            [10, 30, 60, 0, 70, 40],\n",
        "            [80, 100, 30, 70, 0, 50],\n",
        "            [20, 80, 10, 40, 50, 0]]).astype(np.float32)\n",
        "\n",
        "# A = np.random.rand(rows, cols).astype(np.float32)\n",
        "# B = np.random.rand(rows, cols).astype(np.float32)\n",
        "\n",
        "# Crear matrices vacías para almacenar el resultado en la CPU\n",
        "C = np.empty_like(A).astype(np.float32)\n",
        "\n",
        "# Definir las dimensiones del bloque y la cuadrícula\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid_x = (A.shape[0] + threads_per_block[0] - 1) // threads_per_block[0]\n",
        "blocks_per_grid_y = (A.shape[1] + threads_per_block[1] - 1) // threads_per_block[1]\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
        "\n",
        "# Transfiere los datos a la GPU\n",
        "d_A = cuda.to_device(A)\n",
        "d_B = cuda.to_device(B)\n",
        "d_C = cuda.to_device(C)\n",
        "\n",
        "\n",
        "# Llama a la función en la GPU\n",
        "add_matrices_on_gpu[blocks_per_grid, threads_per_block](d_A, d_B, d_C)\n",
        "\n",
        "print(A.shape[0])\n",
        "\n",
        "# Transfiere el resultado de nuevo a la CPU\n",
        "d_C.copy_to_host(C)\n",
        "\n",
        "# Imprime el resultado\n",
        "print(\"Matriz A:\")\n",
        "print(A)\n",
        "print(\"Matriz B:\")\n",
        "print(B)\n",
        "print(\"Resultado de la suma:\")\n",
        "print(C)\n"
      ],
      "metadata": {
        "id": "nTY-dfvIxchw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "076526c3-4316-4714-f64e-46ba019dbfb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "Matriz A:\n",
            "[[  0.  40.  50.  10.  80.  20.]\n",
            " [ 40.   0.  90.  30. 100.  80.]\n",
            " [ 50.  90.   0.  60.  30.  10.]\n",
            " [ 10.  30.  60.   0.  70.  40.]\n",
            " [ 80. 100.  30.  70.   0.  50.]\n",
            " [ 20.  80.  10.  40.  50.   0.]]\n",
            "Matriz B:\n",
            "[[  0.  40.  50.  10.  80.  20.]\n",
            " [ 40.   0.  90.  30. 100.  80.]\n",
            " [ 50.  90.   0.  60.  30.  10.]\n",
            " [ 10.  30.  60.   0.  70.  40.]\n",
            " [ 80. 100.  30.  70.   0.  50.]\n",
            " [ 20.  80.  10.  40.  50.   0.]]\n",
            "Resultado de la suma:\n",
            "[[  0.  80. 100.  20. 160.  40.]\n",
            " [ 80.   0. 180.  60. 200. 160.]\n",
            " [100. 180.   0. 120.  60.  20.]\n",
            " [ 20.  60. 120.   0. 140.  80.]\n",
            " [160. 200.  60. 140.   0. 100.]\n",
            " [ 40. 160.  20.  80. 100.   0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda,float32\n",
        "import math\n",
        "import numba\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TVu8TmCNbV7q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy\n",
        "drive.mount('/content/drive')\n",
        "songs = pd.read_csv('/content/drive/My Drive/Colab Notebooks/yataros1.csv',header=None)\n",
        "\n",
        "# dataset_sec_rec=songs.copy()\n",
        "# dataset_sec_rec=dataset_sec_rec.transpose()\n",
        "\n",
        "# dataset_sec_rec.drop(0, axis=1, inplace = True)\n",
        "# dataset_sec_rec = dataset_sec_rec.iloc[1:]\n",
        "# dataset_sec_rec = dataset_sec_rec.reset_index(drop=True)\n",
        "# dataset_sec_rec = dataset_sec_rec.to_numpy()\n",
        "# dataset_sec_rec=dataset_sec_rec.astype(numpy.float32)\n",
        "\n",
        "songs=songs.transpose()\n",
        "# print(songs.isnull().sum())\n",
        "\n",
        "songs.drop(0, axis=1, inplace = True)\n",
        "songs = songs.iloc[1:]\n",
        "songs = songs.reset_index(drop=True)\n",
        "dataset = songs.to_numpy()\n",
        "\n",
        "# dataset=dataset[0:10,0:12]\n",
        "dataset=dataset.astype(numpy.float64)\n",
        "# n=numpy.size(dataset,axis=0)\n",
        "# print(numpy.size(dataset,axis=0),numpy.size(dataset,axis=1))\n",
        "# print(dataset)\n",
        "cents_graph_global=[]\n",
        "# print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5NXaLA7yJrJ",
        "outputId": "f35a3318-96fe-497b-b174-098c86a18de5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rDubmOryTBi",
        "outputId": "4ca31ebe-3940-40e4-83e9-5140dc493853"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.80646314e+03, 1.90046106e+03, 1.80997253e+03, ...,\n",
              "        1.81985717e+03, 1.90887120e+03, 1.79578567e+03],\n",
              "       [1.49390238e+02, 1.53020840e+02, 1.49627115e+02, ...,\n",
              "        1.48267935e+02, 1.56901695e+02, 1.48714949e+02],\n",
              "       [1.51722815e+02, 1.67069848e+02, 1.53549911e+02, ...,\n",
              "        1.58083895e+02, 1.66423507e+02, 1.50564407e+02],\n",
              "       ...,\n",
              "       [3.87574681e-02, 1.09775774e-01, 1.63062430e-01, ...,\n",
              "        1.54991645e-01, 2.22071003e-01, 2.36816106e-02],\n",
              "       [5.02914177e+00, 4.24687834e+00, 7.32199789e+00, ...,\n",
              "        4.92034191e+00, 2.51490243e+00, 2.54902411e+00],\n",
              "       [9.49662362e-01, 9.21523196e-01, 9.09609639e-01, ...,\n",
              "        9.51174754e-01, 8.85426506e-01, 9.70989426e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cHLAxk5TxPQJ"
      },
      "outputs": [],
      "source": [
        "@cuda.jit\n",
        "def edm(X_d,N,F,D_d):\n",
        "    thisRow,otherRow = cuda.grid(2)\n",
        "    if thisRow < N and otherRow < N:\n",
        "      d = 0.0\n",
        "      for f in range(F):\n",
        "        d += (X_d[thisRow, f] - X_d[otherRow, f]) **2\n",
        "      D_d[thisRow, otherRow] = math.sqrt(d)\n",
        "\n",
        "@cuda.jit\n",
        "def KCentresGPU(D_d,K_d,L_d,N,K):\n",
        "    i = cuda.grid(1)\n",
        "    minimum=math.inf\n",
        "    pos=-1\n",
        "    if i < N:\n",
        "      for k in range(K):\n",
        "        kk=K_d[k]\n",
        "        if D_d[i,kk]<minimum:\n",
        "          minimum=D_d[i,kk]\n",
        "          pos=k\n",
        "      L_d[i]=pos\n",
        "\n",
        "@cuda.jit\n",
        "def findMaximaGPU(D_d,L_d,M_d,N):\n",
        "    i = cuda.grid(1)\n",
        "    maximum=-1.0\n",
        "    if i < N:\n",
        "      cluster_label=L_d[i]\n",
        "      for j in range(N):\n",
        "        if cluster_label==L_d[j]:\n",
        "          if D_d[i,j]>maximum:\n",
        "            maximum=D_d[i,j]\n",
        "      M_d[cluster_label,i]=maximum\n",
        "\n",
        "@cuda.jit\n",
        "def findMinimumOfMaximaGPU(t_d,M_d,N,K):\n",
        "    k = cuda.grid(1)\n",
        "    minimum=math.inf\n",
        "    if k < K:\n",
        "      for j in range(N):\n",
        "        if M_d[k,j]<minimum:\n",
        "          minimum=M_d[k,j]\n",
        "          pos=j\n",
        "      t_d[k]=pos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from timeit import default_timer\n",
        "import time\n",
        "\n",
        "def main(dataset,k,nrep=1):\n",
        "  elapsed_time=0\n",
        "  N=dataset.shape[0]\n",
        "  F=dataset.shape[1]\n",
        "  X_d = cuda.to_device(dataset)\n",
        "\n",
        "  mat_dis=numpy.empty([N, N])\n",
        "  mat_dis = mat_dis.astype(numpy.float32)\n",
        "  mat_dis_gpu=cuda.to_device(mat_dis)\n",
        "\n",
        "  threads_per_block = (32, 32)\n",
        "  blocks_per_grid_x = (N + threads_per_block[0] - 1) // threads_per_block[0]\n",
        "  blocks_per_grid_y = (N + threads_per_block[1] - 1) // threads_per_block[1]\n",
        "  blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
        "\n",
        "\n",
        "  block=32\n",
        "  grid=int((N + block - 1) / block)\n",
        "\n",
        "  L=numpy.full((N),-1,dtype=numpy.int32)\n",
        "  L_d=cuda.to_device(L)\n",
        "\n",
        "  M=numpy.full((k,N),numpy.inf)\n",
        "  M = M.astype(numpy.float32)\n",
        "  M_d = cuda.to_device(M)\n",
        "\n",
        "  t=numpy.full((k),-1,dtype=numpy.int32)\n",
        "  t_d=cuda.to_device(t)\n",
        "  dopt=numpy.inf\n",
        "  cents_graph_Numba_c=[]\n",
        "\n",
        "\n",
        "\n",
        "  inicio=default_timer()\n",
        "\n",
        "  ##MEDIDA\n",
        "  start_time = time.time()\n",
        "  edm[blocks_per_grid, threads_per_block](X_d, N,F,mat_dis_gpu)\n",
        "  finish_time = time.time()\n",
        "\n",
        "  print(\"Tiempo de Matriz de distancias: \",finish_time-start_time)\n",
        "\n",
        "  mat_dis_gpu.copy_to_host(mat_dis)\n",
        "\n",
        "  for i in range(nrep):\n",
        "    # K_h=numpy.random.permutation(N)\n",
        "    # K_h=K_h[0:k]\n",
        "    # K_h = K_h.astype(numpy.int32)\n",
        "    # K_d=cuda.to_device(K_h)\n",
        "\n",
        "    #inicialización de K\n",
        "    K_h=np.array([3, 14, 35, 24, 39], dtype=np.int32)\n",
        "    K_d=cuda.to_device(K_h)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    while True:\n",
        "      # print(\"Vea esto es M\", K_h)\n",
        "      ##MEDIDA\n",
        "      KCentresGPU[grid,block](mat_dis_gpu,K_d,L_d,N,k)\n",
        "      findMaximaGPU[grid,block](mat_dis_gpu,L_d,M_d,N)\n",
        "      findMinimumOfMaximaGPU[grid,block](t_d,M_d,N,k)\n",
        "\n",
        "\n",
        "\n",
        "      # K_d.copy_to_host(K_h)\n",
        "      t_d.copy_to_host(t)\n",
        "\n",
        "\n",
        "      # print(\"Esto es k_h \", K_h, \"hace las veces de M\")\n",
        "      # print(\"Esto es t\", t, \"hace las veces de J\")\n",
        "      if np.all(K_h==t):\n",
        "        # print(\"CONVERGE\")\n",
        "        dmin,labs=numpy.min(mat_dis[t,:],axis=0),numpy.argmin(mat_dis[t,:],axis=0)\n",
        "        dmin=numpy.max(dmin)\n",
        "        break\n",
        "      K_h=t.copy()\n",
        "      K_d.copy_to_device(t_d)\n",
        "\n",
        "    finish_time = time.time()\n",
        "    elapsed_time+=(finish_time-start_time)\n",
        "    #almacena los centros más optimos en jopt.\n",
        "    if(dmin<=dopt):\n",
        "        dopt=dmin\n",
        "        labels=numpy.transpose(labs)\n",
        "        jopt=t.tolist()\n",
        "\n",
        "\n",
        "  #Determina los mejores centros sobre los N intentos.\n",
        "  dm=numpy.zeros(k_length)\n",
        "  for i in range(k_length):\n",
        "      L=numpy.where(labels==i)[0]\n",
        "      dm[i]=numpy.max(mat_dis[jopt[i],L])\n",
        "\n",
        "  cents_graph_global.append(cents_graph_Numba_c)\n",
        "  fin=default_timer()\n",
        "\n",
        "  print(\"\\nTiempo de K-centres:\",elapsed_time/nrep)\n",
        "  return labels,jopt,dm\n",
        "\n",
        "\n",
        "\n",
        "k_length=5\n",
        "# inicio=default_timer()\n",
        "labels,jopt,dm=main(dataset,k_length,25)\n",
        "# fin=default_timer()\n",
        "# print(fin-inicio)\n",
        "print(\"\\n\",labels,dm)\n",
        "\n",
        "print(\"\\nCENTROIDES :\",jopt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4f5hDMl_KtI",
        "outputId": "789f6f5d-dcc1-4b68-e470-17ce66756ec7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c8bfa7c26666>:11: RuntimeWarning: overflow encountered in cast\n",
            "  mat_dis = mat_dis.astype(numpy.float32)\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de Matriz de distancias:  0.31762123107910156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tiempo de K-centres: 0.02115602493286133\n",
            "\n",
            " [2 3 3 3 3 1 4 1 1 4 1 1 1 1 1 1 1 2 0 0 0 2 0 1 1 1 1 1 1 1 1 4 1 3 1 4 1\n",
            " 1 4 1] [1.87170368e+08 9.36759720e+01 3.03671406e+05 1.35219824e+04\n",
            " 8.05443726e+02]\n",
            "\n",
            "CENTROIDES : [18, 24, 0, 2, 9]\n"
          ]
        }
      ]
    }
  ]
}